{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# here put the import lib\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "def sigmoid(inX):\n",
    "    '''\n",
    "    @description: sigmoid函数\n",
    "    @param  inX - 数据\n",
    "    @return: sigmoid函数\n",
    "    '''\n",
    "    return 1.0 / (1 + np.exp(-inX))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def gradAscent(dataMatIn, classLabels):\n",
    "    '''\n",
    "        @description: 梯度上升法\n",
    "        @param {type} 两个参数：\n",
    "        第一个参数==> dataMatIn 是一个2维NumPy数组，每列分别代表每个不同的特征，每行则代表每个训练样本。\n",
    "        第二个参数==> classLabels 是类别标签，它是一个 1*100 的行向量。为了便于矩阵计算，需要将该行向量转换为列向量，做法是将原向量转置，再将它赋值给labelMat。\n",
    "        @return: 求得的权重数组(最优参数)\n",
    "    '''\n",
    "    #用dataMatIn创建特征矩阵\n",
    "    dataMatrix = np.mat(dataMatIn)\n",
    "    #调换矩阵的坐标顺序，对于二维矩阵来说，transpose()就是转置\n",
    "    labelMat = np.mat(classLabels).transpose()\n",
    "    #m是样本数，n是特征数\n",
    "    m, n = np.shape(dataMatrix)\n",
    "    #梯度上升步长\n",
    "    alpha = 0.001\n",
    "    #最大迭代次数\n",
    "    maxCycles = 500\n",
    "    #权重向量b，初始化为全1 这里面n为3\n",
    "    weights = np.ones((n, 1))\n",
    "    for k in range(maxCycles):\n",
    "        #讲给定的值通过sigmoid函数输出为0-1之间的数值 #对w1*x1+w2*x2求对数几率回归\n",
    "        h = sigmoid(dataMatrix * weights)\n",
    "        #计算真实值和预测值之间的误差\n",
    "        error = labelMat - h\n",
    "        #根据误差进行梯度更新\n",
    "        weights = weights + alpha * dataMatrix.transpose() * error\n",
    "    #.getA()将自身矩阵变量转化为ndarray类型的变量\n",
    "    return weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def stocGradAscent1(dataMatrix, classLabels, numIter=150):\n",
    "    '''\n",
    "        @description: 改进的随机梯度上升算法\n",
    "        @param  dataMatrix - 数据数组\n",
    "            classLabels - 数据标签\n",
    "            numIter - 迭代次数\n",
    "        @return: weights - 求得的回归系数数组(最优参数)\n",
    "    '''\n",
    "    #返回dataMatrix的大小。m为行数,n为列数。\n",
    "    m,n = np.shape(dataMatrix)\n",
    "    #参数初始化\n",
    "    weights = np.ones(n)\n",
    "    # 随机梯度, 循环150,观察是否收敛\n",
    "    for j in range(numIter):\n",
    "        # [0, 1, 2 .. m-1]\n",
    "        dataIndex = list(range(m))\n",
    "        for i in range(m):\n",
    "            # i和j的不断增大，导致alpha的值不断减少，但是不为0\n",
    "            alpha = 4/(1.0+j+i)+0.0001\n",
    "            # 随机产生一个 0～len()之间的一个值\n",
    "            # random.uniform(x, y) 方法将随机生成下一个实数，它在[x,y]范围内,x是这个范围内的最小值，y是这个范围内的最大值。\n",
    "            randIndex = int(np.random.uniform(0,len(dataIndex)))\n",
    "            # sum(dataMatrix[i]*weights)为了求 f(x)的值， f(x)=a1*x1+b2*x2+..+nn*xn\n",
    "            h = sigmoid(sum(dataMatrix[randIndex]*weights))\n",
    "            error = classLabels[randIndex] - h\n",
    "            #更新回归系数\n",
    "            weights = weights + alpha * error * dataMatrix[randIndex]\n",
    "            #删除已经使用的样本\n",
    "            del(dataIndex[randIndex])\n",
    "    return weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def classifyVector(inX, weights):\n",
    "    prob = sigmoid(sum(inX*weights))\n",
    "    if prob > 0.5: return 1.0\n",
    "    else: return 0.0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def colicTest():\n",
    "    train_path = ''\n",
    "    test_path = ''\n",
    "    frTrain = open('C:/Users/Administrator/Desktop/blog/github/AILearners/data/ml/jqxxsz/5.Logistic/horseColicTraining.txt')                                        #打开训练集\n",
    "    frTest = open('C:/Users/Administrator/Desktop/blog/github/AILearners/data/ml/jqxxsz/5.Logistic/horseColicTest.txt')                                                #打开测试集\n",
    "    trainingSet = []\n",
    "    trainingLabels = []\n",
    "    for line in frTrain.readlines():\n",
    "        currLine = line.strip().split('\\t')\n",
    "        lineArr = []\n",
    "        for i in range(len(currLine)-1):\n",
    "            lineArr.append(float(currLine[i]))\n",
    "        trainingSet.append(lineArr)\n",
    "        trainingLabels.append(float(currLine[-1]))\n",
    "    #使用梯度上升训练\n",
    "    trainWeights = gradAscent(np.array(trainingSet), trainingLabels)\n",
    "    errorCount = 0; numTestVec = 0.0\n",
    "    for line in frTest.readlines():\n",
    "        numTestVec += 1.0\n",
    "        currLine = line.strip().split('\\t')\n",
    "        lineArr =[]\n",
    "        for i in range(len(currLine)-1):\n",
    "            lineArr.append(float(currLine[i]))\n",
    "        if int(classifyVector(np.array(lineArr), trainWeights[:,0]))!= int(currLine[-1]):\n",
    "            errorCount += 1\n",
    "    errorRate = (float(errorCount)/numTestVec) * 100\n",
    "    print(\"梯度上升算法测试集错误率为: %.2f%%\" % errorRate).decode('utf-8').encode('gb2312')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def colicTest1():\n",
    "    frTrain = open('C:/Users/Administrator/Desktop/blog/github/AILearners/data/ml/jqxxsz/5.Logistic/horseColicTraining.txt')                                        #打开训练集\n",
    "    frTest = open('C:/Users/Administrator/Desktop/blog/github/AILearners/data/ml/jqxxsz/5.Logistic/horseColicTest.txt')                                                #打开测试集\n",
    "    trainingSet = []; trainingLabels = []\n",
    "    for line in frTrain.readlines():\n",
    "        currLine = line.strip().split('\\t')\n",
    "        lineArr = []\n",
    "        for i in range(len(currLine)-1):\n",
    "            lineArr.append(float(currLine[i]))\n",
    "        trainingSet.append(lineArr)\n",
    "        trainingLabels.append(float(currLine[-1]))\n",
    "    #使用改进的随机上升梯度训练\n",
    "    trainWeights = stocGradAscent1(np.array(trainingSet), trainingLabels)\n",
    "    errorCount = 0; numTestVec = 0.0\n",
    "    for line in frTest.readlines():\n",
    "        numTestVec += 1.0\n",
    "        currLine = line.strip().split('\\t')\n",
    "        lineArr =[]\n",
    "        for i in range(len(currLine)-1):\n",
    "            lineArr.append(float(currLine[i]))\n",
    "        if int(classifyVector(np.array(lineArr), trainWeights))!= int(currLine[-1]):\n",
    "            errorCount += 1\n",
    "    errorRate = (float(errorCount)/numTestVec) * 100                                 #错误率计算\n",
    "    print(\"随机梯度上升测试集错误率为: %.2f%%\" % errorRate).decode('utf-8').encode('gb2312')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#使用梯度上升训练\n",
    "colicTest()\n",
    "#使用随机梯度上升训练\n",
    "colicTest1()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}