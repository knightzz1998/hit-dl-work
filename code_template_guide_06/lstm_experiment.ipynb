{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "sys.version_info(major=3, minor=7, micro=11, releaselevel='final', serial=0)\n",
      "matplotlib 3.4.2\n",
      "numpy 1.18.5\n",
      "pandas 1.3.3\n",
      "sklearn 1.0\n",
      "tensorflow 2.3.0\n",
      "tensorflow.keras 2.4.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "# print(\"GPU : \", tf.test.is_gpu_available())\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1. 数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5101618\n",
      " aer banknote berlitz calloway centrust cluett fromstein gitano guterman hydro-quebec ipo kia memote\n"
     ]
    }
   ],
   "source": [
    "text = open(\"./data/ptb.train.txt\", \"r\").read()\n",
    "print(len(text))\n",
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 构建词表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "['\\n', ' ', '#', '$', '&', \"'\", '*', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '<', '>', 'N', '\\\\', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "# 构建词表\n",
    "vocab = sorted(set(text))\n",
    "print(len(vocab))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n' ' ' '#' '$' '&' \"'\" '*' '-' '.' '/' '0' '1' '2' '3' '4' '5' '6' '7'\n",
      " '8' '9' '<' '>' 'N' '\\\\' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l'\n",
      " 'm' 'n' 'o' 'p' 'q' 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z' 'unk']\n"
     ]
    }
   ],
   "source": [
    "# 添加 <unk>\n",
    "vocab.append(\"unk\")\n",
    "id2char = np.array(vocab)\n",
    "print(id2char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '#': 2, '$': 3, '&': 4, \"'\": 5, '*': 6, '-': 7, '.': 8, '/': 9, '0': 10, '1': 11, '2': 12, '3': 13, '4': 14, '5': 15, '6': 16, '7': 17, '8': 18, '9': 19, '<': 20, '>': 21, 'N': 22, '\\\\': 23, 'a': 24, 'b': 25, 'c': 26, 'd': 27, 'e': 28, 'f': 29, 'g': 30, 'h': 31, 'i': 32, 'j': 33, 'k': 34, 'l': 35, 'm': 36, 'n': 37, 'o': 38, 'p': 39, 'q': 40, 'r': 41, 's': 42, 't': 43, 'u': 44, 'v': 45, 'w': 46, 'x': 47, 'y': 48, 'z': 49, 'unk': 50}\n"
     ]
    }
   ],
   "source": [
    "# 构建词表索引\n",
    "char2index = {char: index for index, char in enumerate(vocab)}\n",
    "# 添加新的 <unk> 词表\n",
    "print(char2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " aer bankn\n",
      "[ 1 24 28 41  1 25 24 37 34 37]\n"
     ]
    }
   ],
   "source": [
    "# 将字符转换为词表索引\n",
    "text_as_int = np.array([char2index[c] for c in text])\n",
    "print(text[:10])\n",
    "print(text_as_int[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32)  \n",
      "tf.Tensor(24, shape=(), dtype=int32) a\n",
      "tf.Tensor(\n",
      "[ 1 24 28 41  1 25 24 37 34 37 38 43 28  1 25 28 41 35 32 43 49  1 26 24\n",
      " 35 35 38 46 24 48  1 26 28 37 43 41 44 42 43  1 26 35 44 28 43 43  1 29\n",
      " 41 38 36 42 43 28 32 37  1 30 32 43 24 37 38  1 30 44 43 28 41 36 24 37\n",
      "  1 31 48 27 41 38  7 40 44 28 25 28 26  1 32 39 38  1 34 32 24  1 36 28\n",
      " 36 38 43 28 26], shape=(101,), dtype=int32)\n",
      "'  a e r   b a n k n o t e   b e r l i t z   c a l l o w a y   c e n t r u s t   c l u e t t   f r o m s t e i n   g i t a n o   g u t e r m a n   h y d r o - q u e b e c   i p o   k i a   m e m o t e c'\n",
      "tf.Tensor(\n",
      "[ 1 36 35 47  1 37 24 31 25  1 39 44 37 43 42  1 41 24 34 28  1 41 28 30\n",
      " 24 43 43 24  1 41 44 25 28 37 42  1 42 32 36  1 42 37 24 26 34  7 29 38\n",
      " 38 27  1 42 42 24 37 30 48 38 37 30  1 42 46 24 39 38  1 46 24 26 31 43\n",
      " 28 41  1  0  1 39 32 28 41 41 28  1 20 44 37 34 21  1 22  1 48 28 24 41\n",
      " 42  1 38 35 27], shape=(101,), dtype=int32)\n",
      "'  m l x   n a h b   p u n t s   r a k e   r e g a t t a   r u b e n s   s i m   s n a c k - f o o d   s s a n g y o n g   s w a p o   w a c h t e r   \\n   p i e r r e   < u n k >   N   y e a r s   o l d'\n"
     ]
    }
   ],
   "source": [
    "def split_input_target(id_index):\n",
    "    \"\"\"\n",
    "        abcde -> abcd , bcde\n",
    "    :param id_index:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return id_index[:-1], id_index[1:]\n",
    "\n",
    "\n",
    "# 将词表转换为数据集\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)  # text_as_int 是转换为索引的 text\n",
    "\n",
    "# 对数据设置batch, 将字符集的dataset转换为句子级的dataset\n",
    "seq_length = 100  # 设置句子长度\n",
    "# 加一的原因是 split_input_target 返回的长度比输入的长度少1\n",
    "# drop_remainder \" 如果数据到最后无法组成一个 batch 时丢弃该数据\n",
    "seq_dataset = char_dataset.batch(seq_length + 1, drop_remainder=True)\n",
    "\n",
    "# 打印数据\n",
    "# char_dataset 每一个元素都是字符\n",
    "for ch_id in char_dataset.take(2):  # 获取两个数据\n",
    "    print(ch_id, id2char[ch_id.numpy()])\n",
    "\n",
    "# seq_dataset ,每一个元素都是句子\n",
    "for seq_id in seq_dataset.take(2):\n",
    "    print(seq_id)\n",
    "    print(repr(\" \".join(id2char[seq_id.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 24 28 41  1 25 24 37 34 37 38 43 28  1 25 28 41 35 32 43 49  1 26 24\n",
      " 35 35 38 46 24 48  1 26 28 37 43 41 44 42 43  1 26 35 44 28 43 43  1 29\n",
      " 41 38 36 42 43 28 32 37  1 30 32 43 24 37 38  1 30 44 43 28 41 36 24 37\n",
      "  1 31 48 27 41 38  7 40 44 28 25 28 26  1 32 39 38  1 34 32 24  1 36 28\n",
      " 36 38 43 28] [24 28 41  1 25 24 37 34 37 38 43 28  1 25 28 41 35 32 43 49  1 26 24 35\n",
      " 35 38 46 24 48  1 26 28 37 43 41 44 42 43  1 26 35 44 28 43 43  1 29 41\n",
      " 38 36 42 43 28 32 37  1 30 32 43 24 37 38  1 30 44 43 28 41 36 24 37  1\n",
      " 31 48 27 41 38  7 40 44 28 25 28 26  1 32 39 38  1 34 32 24  1 36 28 36\n",
      " 38 43 28 26]\n",
      "[ 1 36 35 47  1 37 24 31 25  1 39 44 37 43 42  1 41 24 34 28  1 41 28 30\n",
      " 24 43 43 24  1 41 44 25 28 37 42  1 42 32 36  1 42 37 24 26 34  7 29 38\n",
      " 38 27  1 42 42 24 37 30 48 38 37 30  1 42 46 24 39 38  1 46 24 26 31 43\n",
      " 28 41  1  0  1 39 32 28 41 41 28  1 20 44 37 34 21  1 22  1 48 28 24 41\n",
      " 42  1 38 35] [36 35 47  1 37 24 31 25  1 39 44 37 43 42  1 41 24 34 28  1 41 28 30 24\n",
      " 43 43 24  1 41 44 25 28 37 42  1 42 32 36  1 42 37 24 26 34  7 29 38 38\n",
      " 27  1 42 42 24 37 30 48 38 37 30  1 42 46 24 39 38  1 46 24 26 31 43 28\n",
      " 41  1  0  1 39 32 28 41 41 28  1 20 44 37 34 21  1 22  1 48 28 24 41 42\n",
      "  1 38 35 27]\n"
     ]
    }
   ],
   "source": [
    "# 使用 split_input_target 对句子进行处理\n",
    "seq_dataset = seq_dataset.map(split_input_target)\n",
    "\n",
    "for item_input, item_output in seq_dataset.take(2):\n",
    "    print(item_input.numpy(), item_output.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "buffer_size = 10000\n",
    "seq_dataset = seq_dataset.shuffle(buffer_size).batch(batch_size=batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2. 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 词表大小\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024  # rnn 输入大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    \"\"\"\n",
    "        构建模型\n",
    "    :param vocab_size:\n",
    "    :param embedding_dim:\n",
    "    :param rnn_units:\n",
    "    :param batch_size:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
    "        keras.layers.SimpleRNN(units=rnn_units, return_sequences=True),\n",
    "        keras.layers.Dense(vocab_size),\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 注意 : Cannot convert a symbolic Tensor (simple_rnn_5/strided_slice:0) to a numpy array\n",
    "- 如果出现以上报错, 是numpy不兼容导致, 可以删除numpy重新下载 1.18.5版本\n",
    "- tensorflow 2.3.0 requires 1.16.0<=numpy<1.19.0,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (64, None, 256)           13056     \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (64, None, 1024)          1311744   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (64, None, 51)            52275     \n",
      "=================================================================\n",
      "Total params: 1,377,075\n",
      "Trainable params: 1,377,075\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(vocab_size=vocab_size,\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    rnn_units=rnn_units,\n",
    "                    batch_size=batch_size)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 51)\n",
      "tf.Tensor(\n",
      "[[[ 1.01326741e-02 -4.24239598e-02 -3.46165262e-02 ...  6.72607962e-03\n",
      "    7.18212267e-03 -1.71390101e-02]\n",
      "  [ 1.63018480e-02 -5.63163087e-02  4.08628136e-02 ...  3.66522111e-02\n",
      "   -4.00835164e-02 -2.56150290e-02]\n",
      "  [-4.51371539e-03 -1.34219415e-02  5.82773685e-02 ...  6.69930875e-02\n",
      "   -3.11735608e-02  6.81254640e-02]\n",
      "  ...\n",
      "  [-6.03021532e-02 -4.67936061e-02 -1.62060633e-01 ...  2.74062306e-01\n",
      "   -5.31082526e-02 -4.72390652e-02]\n",
      "  [-3.61921079e-02  2.10722134e-01  3.67143005e-03 ...  2.85651833e-02\n",
      "    1.89557046e-01 -6.77676722e-02]\n",
      "  [-7.47772530e-02  5.70588671e-02 -4.16901819e-02 ... -1.79651141e-01\n",
      "   -6.75115585e-02  8.55469629e-02]]\n",
      "\n",
      " [[-6.20439053e-02  3.82665545e-02  7.30050653e-02 ... -1.77581403e-02\n",
      "   -1.16553176e-02 -8.24929215e-03]\n",
      "  [-2.47679185e-04 -1.44483494e-02 -2.65385509e-02 ...  5.31017259e-02\n",
      "    2.15319078e-02  1.83974132e-02]\n",
      "  [ 5.23698628e-02 -5.71615957e-02 -5.80306984e-02 ...  6.97944239e-02\n",
      "    2.71769222e-02 -1.25371153e-05]\n",
      "  ...\n",
      "  [-5.25974780e-02 -1.90085024e-01 -2.01914176e-01 ... -1.33121878e-01\n",
      "   -1.67093173e-01 -1.52251467e-01]\n",
      "  [ 8.83597806e-02 -1.11416951e-01 -1.28257111e-01 ... -2.78522164e-01\n",
      "    1.10299364e-02  4.83440459e-02]\n",
      "  [-8.43025744e-02 -2.23923683e-01 -1.00933075e-01 ...  1.33783817e-01\n",
      "   -4.36781719e-03  2.24249363e-01]]], shape=(2, 100, 51), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 可以直接吧model当做函数来用, 直接输出 (batch_size, seq_length, vocab_size)\n",
    "# 输出的相当于概率分布\n",
    "for input_example_batch, target_example_batch in seq_dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape)\n",
    "    print(example_batch_predictions[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[26]\n",
      " [24]\n",
      " [11]\n",
      " [15]\n",
      " [31]\n",
      " [23]\n",
      " [ 8]\n",
      " [44]\n",
      " [30]\n",
      " [12]\n",
      " [ 9]\n",
      " [31]\n",
      " [48]\n",
      " [35]\n",
      " [36]\n",
      " [28]\n",
      " [16]\n",
      " [29]\n",
      " [27]\n",
      " [15]\n",
      " [47]\n",
      " [32]\n",
      " [10]\n",
      " [37]\n",
      " [28]\n",
      " [24]\n",
      " [47]\n",
      " [21]\n",
      " [29]\n",
      " [19]\n",
      " [38]\n",
      " [50]\n",
      " [38]\n",
      " [41]\n",
      " [22]\n",
      " [36]\n",
      " [41]\n",
      " [46]\n",
      " [ 3]\n",
      " [48]\n",
      " [ 1]\n",
      " [ 6]\n",
      " [23]\n",
      " [28]\n",
      " [49]\n",
      " [11]\n",
      " [ 4]\n",
      " [ 0]\n",
      " [28]\n",
      " [36]\n",
      " [ 6]\n",
      " [41]\n",
      " [13]\n",
      " [36]\n",
      " [27]\n",
      " [24]\n",
      " [39]\n",
      " [19]\n",
      " [ 4]\n",
      " [ 9]\n",
      " [22]\n",
      " [25]\n",
      " [ 3]\n",
      " [35]\n",
      " [43]\n",
      " [44]\n",
      " [33]\n",
      " [48]\n",
      " [ 9]\n",
      " [ 0]\n",
      " [ 8]\n",
      " [ 4]\n",
      " [26]\n",
      " [46]\n",
      " [22]\n",
      " [50]\n",
      " [42]\n",
      " [36]\n",
      " [47]\n",
      " [44]\n",
      " [23]\n",
      " [16]\n",
      " [ 6]\n",
      " [38]\n",
      " [ 7]\n",
      " [20]\n",
      " [11]\n",
      " [36]\n",
      " [35]\n",
      " [22]\n",
      " [15]\n",
      " [35]\n",
      " [27]\n",
      " [19]\n",
      " [ 9]\n",
      " [12]\n",
      " [26]\n",
      " [18]\n",
      " [38]\n",
      " [12]], shape=(100, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[26 24 11 15 31 23  8 44 30 12  9 31 48 35 36 28 16 29 27 15 47 32 10 37\n",
      " 28 24 47 21 29 19 38 50 38 41 22 36 41 46  3 48  1  6 23 28 49 11  4  0\n",
      " 28 36  6 41 13 36 27 24 39 19  4  9 22 25  3 35 43 44 33 48  9  0  8  4\n",
      " 26 46 22 50 42 36 47 44 23 16  6 38  7 20 11 36 35 22 15 35 27 19  9 12\n",
      " 26 18 38 12], shape=(100,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# 1. 随机采样\n",
    "# 2. 贪心\n",
    "# 3. logits : 在计算分类问题总, softmax 之前的值就是logits\n",
    "# num_samples 指定产生多个序列\n",
    "sample_indices = tf.random.categorical(logits=example_batch_predictions[0], num_samples=1)\n",
    "print(sample_indices)\n",
    "sample_indices = tf.squeeze(sample_indices, axis=-1)\n",
    "print(sample_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input  't e d   t o   b e g i n   i n   m a r c h   \\n   u . s .   l a w   r e q u i r e s   c r i m i n a l   d e f e n d a n t s   t o   t u r n   o v e r   f o r e i g n   d o c u m e n t s   s u c h   a s'\n",
      "Output  'e d   t o   b e g i n   i n   m a r c h   \\n   u . s .   l a w   r e q u i r e s   c r i m i n a l   d e f e n d a n t s   t o   t u r n   o v e r   f o r e i g n   d o c u m e n t s   s u c h   a s  '\n",
      "Prediction   'c a 1 5 h \\\\ . u g 2 / h y l m e 6 f d 5 x i 0 n e a x > f 9 o unk o r N m r w $ y   * \\\\ e z 1 & \\n e m * r 3 m d a p 9 & / N b $ l t u j y / \\n . & c w N unk s m x u \\\\ 6 * o - < 1 m l N 5 l d 9 / 2 c 8 o 2'\n"
     ]
    }
   ],
   "source": [
    "# 打印输入和输出\n",
    "print(\"Input \", repr(\" \".join(id2char[input_example_batch[0]])))\n",
    "print(\"Output \", repr(\" \".join(id2char[target_example_batch[0]])))\n",
    "print(\"Prediction  \", repr(\" \".join(id2char[sample_indices])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3. 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return keras.losses.sparse_categorical_crossentropy(\n",
    "        labels, logits, from_logits=True # 因为预测值是 logits , 所以需要设置为 true\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100)\n",
      "3.9577596\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=loss)\n",
    "\n",
    "# 计算loss\n",
    "example_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(example_loss.shape)\n",
    "print(example_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4. 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 31/789 [>.............................] - ETA: 16:13 - loss: 2.4958"
     ]
    }
   ],
   "source": [
    "# 定义文件夹保存模型\n",
    "output_dir = \"./text_generation_checkpoints\"\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "checkpoint_prefix = os.path.join(output_dir, 'ckpt_{epoch}')\n",
    "# 定义回调函数\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix, save_weights_only=True\n",
    ")\n",
    "\n",
    "epochs = 5\n",
    "history = model.fit(seq_dataset, epochs=epochs, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}