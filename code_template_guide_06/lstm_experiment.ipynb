{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "WARNING:tensorflow:From C:\\Users\\WANGTI~1\\AppData\\Local\\Temp/ipykernel_25324/523647487.py:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU :  True\n",
      "sys.version_info(major=3, minor=7, micro=11, releaselevel='final', serial=0)\n",
      "matplotlib 3.4.3\n",
      "numpy 1.18.5\n",
      "pandas 1.3.2\n",
      "sklearn 0.24.2\n",
      "tensorflow 2.3.0\n",
      "tensorflow.keras 2.4.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(\"GPU : \", tf.test.is_gpu_available())\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1. 数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5101618\n",
      " aer banknote berlitz calloway centrust cluett fromstein gitano guterman hydro-quebec ipo kia memote\n"
     ]
    }
   ],
   "source": [
    "text = open(\"./data/ptb.train.txt\", \"r\").read()\n",
    "print(len(text))\n",
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 构建词表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "['\\n', ' ', '#', '$', '&', \"'\", '*', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '<', '>', 'N', '\\\\', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "# 构建词表\n",
    "vocab = sorted(set(text))\n",
    "print(len(vocab))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n' ' ' '#' '$' '&' \"'\" '*' '-' '.' '/' '0' '1' '2' '3' '4' '5' '6' '7'\n",
      " '8' '9' '<' '>' 'N' '\\\\' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l'\n",
      " 'm' 'n' 'o' 'p' 'q' 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z' 'unk']\n"
     ]
    }
   ],
   "source": [
    "# 添加 <unk>\n",
    "vocab.append(\"unk\")\n",
    "id2char = np.array(vocab)\n",
    "print(id2char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '#': 2, '$': 3, '&': 4, \"'\": 5, '*': 6, '-': 7, '.': 8, '/': 9, '0': 10, '1': 11, '2': 12, '3': 13, '4': 14, '5': 15, '6': 16, '7': 17, '8': 18, '9': 19, '<': 20, '>': 21, 'N': 22, '\\\\': 23, 'a': 24, 'b': 25, 'c': 26, 'd': 27, 'e': 28, 'f': 29, 'g': 30, 'h': 31, 'i': 32, 'j': 33, 'k': 34, 'l': 35, 'm': 36, 'n': 37, 'o': 38, 'p': 39, 'q': 40, 'r': 41, 's': 42, 't': 43, 'u': 44, 'v': 45, 'w': 46, 'x': 47, 'y': 48, 'z': 49, 'unk': 50}\n"
     ]
    }
   ],
   "source": [
    "# 构建词表索引\n",
    "char2index = {char: index for index, char in enumerate(vocab)}\n",
    "# 添加新的 <unk> 词表\n",
    "print(char2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " aer bankn\n",
      "[ 1 24 28 41  1 25 24 37 34 37]\n"
     ]
    }
   ],
   "source": [
    "# 将字符转换为词表索引\n",
    "text_as_int = np.array([char2index[c] for c in text])\n",
    "print(text[:10])\n",
    "print(text_as_int[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32)  \n",
      "tf.Tensor(24, shape=(), dtype=int32) a\n",
      "tf.Tensor(\n",
      "[ 1 24 28 41  1 25 24 37 34 37 38 43 28  1 25 28 41 35 32 43 49  1 26 24\n",
      " 35 35 38 46 24 48  1 26 28 37 43 41 44 42 43  1 26 35 44 28 43 43  1 29\n",
      " 41 38 36 42 43 28 32 37  1 30 32 43 24 37 38  1 30 44 43 28 41 36 24 37\n",
      "  1 31 48 27 41 38  7 40 44 28 25 28 26  1 32 39 38  1 34 32 24  1 36 28\n",
      " 36 38 43 28 26], shape=(101,), dtype=int32)\n",
      "'  a e r   b a n k n o t e   b e r l i t z   c a l l o w a y   c e n t r u s t   c l u e t t   f r o m s t e i n   g i t a n o   g u t e r m a n   h y d r o - q u e b e c   i p o   k i a   m e m o t e c'\n",
      "tf.Tensor(\n",
      "[ 1 36 35 47  1 37 24 31 25  1 39 44 37 43 42  1 41 24 34 28  1 41 28 30\n",
      " 24 43 43 24  1 41 44 25 28 37 42  1 42 32 36  1 42 37 24 26 34  7 29 38\n",
      " 38 27  1 42 42 24 37 30 48 38 37 30  1 42 46 24 39 38  1 46 24 26 31 43\n",
      " 28 41  1  0  1 39 32 28 41 41 28  1 20 44 37 34 21  1 22  1 48 28 24 41\n",
      " 42  1 38 35 27], shape=(101,), dtype=int32)\n",
      "'  m l x   n a h b   p u n t s   r a k e   r e g a t t a   r u b e n s   s i m   s n a c k - f o o d   s s a n g y o n g   s w a p o   w a c h t e r   \\n   p i e r r e   < u n k >   N   y e a r s   o l d'\n"
     ]
    }
   ],
   "source": [
    "def split_input_target(id_index):\n",
    "    \"\"\"\n",
    "        abcde -> abcd , bcde\n",
    "    :param id_index:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return id_index[:-1], id_index[1:]\n",
    "\n",
    "\n",
    "# 将词表转换为数据集\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)  # text_as_int 是转换为索引的 text\n",
    "\n",
    "# 对数据设置batch, 将字符集的dataset转换为句子级的dataset\n",
    "seq_length = 100  # 设置句子长度\n",
    "# 加一的原因是 split_input_target 返回的长度比输入的长度少1\n",
    "# drop_remainder \" 如果数据到最后无法组成一个 batch 时丢弃该数据\n",
    "seq_dataset = char_dataset.batch(seq_length + 1, drop_remainder=True)\n",
    "\n",
    "# 打印数据\n",
    "# char_dataset 每一个元素都是字符\n",
    "for ch_id in char_dataset.take(2):  # 获取两个数据\n",
    "    print(ch_id, id2char[ch_id.numpy()])\n",
    "\n",
    "# seq_dataset ,每一个元素都是句子\n",
    "for seq_id in seq_dataset.take(2):\n",
    "    print(seq_id)\n",
    "    print(repr(\" \".join(id2char[seq_id.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 24 28 41  1 25 24 37 34 37 38 43 28  1 25 28 41 35 32 43 49  1 26 24\n",
      " 35 35 38 46 24 48  1 26 28 37 43 41 44 42 43  1 26 35 44 28 43 43  1 29\n",
      " 41 38 36 42 43 28 32 37  1 30 32 43 24 37 38  1 30 44 43 28 41 36 24 37\n",
      "  1 31 48 27 41 38  7 40 44 28 25 28 26  1 32 39 38  1 34 32 24  1 36 28\n",
      " 36 38 43 28] [24 28 41  1 25 24 37 34 37 38 43 28  1 25 28 41 35 32 43 49  1 26 24 35\n",
      " 35 38 46 24 48  1 26 28 37 43 41 44 42 43  1 26 35 44 28 43 43  1 29 41\n",
      " 38 36 42 43 28 32 37  1 30 32 43 24 37 38  1 30 44 43 28 41 36 24 37  1\n",
      " 31 48 27 41 38  7 40 44 28 25 28 26  1 32 39 38  1 34 32 24  1 36 28 36\n",
      " 38 43 28 26]\n",
      "[ 1 36 35 47  1 37 24 31 25  1 39 44 37 43 42  1 41 24 34 28  1 41 28 30\n",
      " 24 43 43 24  1 41 44 25 28 37 42  1 42 32 36  1 42 37 24 26 34  7 29 38\n",
      " 38 27  1 42 42 24 37 30 48 38 37 30  1 42 46 24 39 38  1 46 24 26 31 43\n",
      " 28 41  1  0  1 39 32 28 41 41 28  1 20 44 37 34 21  1 22  1 48 28 24 41\n",
      " 42  1 38 35] [36 35 47  1 37 24 31 25  1 39 44 37 43 42  1 41 24 34 28  1 41 28 30 24\n",
      " 43 43 24  1 41 44 25 28 37 42  1 42 32 36  1 42 37 24 26 34  7 29 38 38\n",
      " 27  1 42 42 24 37 30 48 38 37 30  1 42 46 24 39 38  1 46 24 26 31 43 28\n",
      " 41  1  0  1 39 32 28 41 41 28  1 20 44 37 34 21  1 22  1 48 28 24 41 42\n",
      "  1 38 35 27]\n"
     ]
    }
   ],
   "source": [
    "# 使用 split_input_target 对句子进行处理\n",
    "seq_dataset = seq_dataset.map(split_input_target)\n",
    "\n",
    "for item_input, item_output in seq_dataset.take(2):\n",
    "    print(item_input.numpy(), item_output.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "buffer_size = 10000\n",
    "seq_dataset = seq_dataset.shuffle(buffer_size).batch(batch_size=batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2. 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 词表大小\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024  # rnn 输入大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    \"\"\"\n",
    "        构建模型\n",
    "    :param vocab_size:\n",
    "    :param embedding_dim:\n",
    "    :param rnn_units:\n",
    "    :param batch_size:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
    "        keras.layers.SimpleRNN(units=rnn_units, return_sequences=True),\n",
    "        keras.layers.Dense(vocab_size),\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 注意 : Cannot convert a symbolic Tensor (simple_rnn_5/strided_slice:0) to a numpy array\n",
    "- 如果出现以上报错, 是numpy不兼容导致, 可以删除numpy重新下载 1.18.5版本\n",
    "- tensorflow 2.3.0 requires 1.16.0<=numpy<1.19.0,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           13056     \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (64, None, 1024)          1311744   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 51)            52275     \n",
      "=================================================================\n",
      "Total params: 1,377,075\n",
      "Trainable params: 1,377,075\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(vocab_size=vocab_size,\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    rnn_units=rnn_units,\n",
    "                    batch_size=batch_size)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 51)\n",
      "tf.Tensor(\n",
      "[[[-1.21233929e-02  2.45017782e-02 -4.84458171e-03 ... -3.48218679e-02\n",
      "   -9.49429441e-03 -1.18255494e-02]\n",
      "  [-4.64975499e-02  3.83330844e-02  6.68234006e-03 ...  2.86842994e-02\n",
      "    3.79523262e-04 -7.01316306e-03]\n",
      "  [-4.76897471e-02  2.53242105e-02 -2.27514021e-02 ...  5.49932197e-02\n",
      "   -4.40298542e-02  4.44192588e-02]\n",
      "  ...\n",
      "  [ 1.12278201e-01  2.07473427e-01  9.15031135e-02 ...  4.53041419e-02\n",
      "   -2.88752645e-01  1.07287735e-01]\n",
      "  [ 1.34028643e-01 -3.34416211e-01 -1.09147966e-01 ...  5.76466918e-02\n",
      "   -3.04285660e-02  2.71576166e-01]\n",
      "  [-1.60031885e-01  1.39257520e-01  1.28557354e-01 ... -2.11957917e-01\n",
      "    1.84943303e-01 -5.75979464e-02]]\n",
      "\n",
      " [[-4.07187361e-03  3.08551490e-02  1.35564189e-02 ... -9.01789032e-03\n",
      "    1.92681439e-02 -3.65005340e-03]\n",
      "  [-3.84491496e-03  6.42496794e-02  3.03850211e-02 ...  5.58115244e-02\n",
      "   -6.27528578e-02 -1.30651481e-02]\n",
      "  [ 1.99169554e-02  2.51578130e-02 -2.91016027e-02 ...  1.28472634e-02\n",
      "   -6.59139603e-02  2.40724683e-02]\n",
      "  ...\n",
      "  [-1.36091471e-01 -5.50041050e-02  1.82805866e-01 ...  9.66450199e-02\n",
      "   -1.00453123e-01  1.97269209e-02]\n",
      "  [-3.67797881e-01 -6.40586019e-02  1.75392389e-01 ...  6.98224008e-02\n",
      "    1.09724574e-01  7.71053880e-02]\n",
      "  [-1.86052516e-01 -3.41947004e-02  8.01671967e-02 ... -2.77812958e-01\n",
      "   -5.61939359e-01 -1.25742450e-01]]], shape=(2, 100, 51), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 可以直接吧model当做函数来用, 直接输出 (batch_size, seq_length, vocab_size)\n",
    "# 输出的相当于概率分布\n",
    "for input_example_batch, target_example_batch in seq_dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape)\n",
    "    print(example_batch_predictions[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1]\n",
      " [42]\n",
      " [38]\n",
      " [19]\n",
      " [44]\n",
      " [35]\n",
      " [15]\n",
      " [46]\n",
      " [50]\n",
      " [14]\n",
      " [19]\n",
      " [20]\n",
      " [19]\n",
      " [ 2]\n",
      " [ 3]\n",
      " [ 7]\n",
      " [ 1]\n",
      " [48]\n",
      " [ 9]\n",
      " [46]\n",
      " [18]\n",
      " [ 6]\n",
      " [ 4]\n",
      " [ 2]\n",
      " [31]\n",
      " [49]\n",
      " [ 3]\n",
      " [16]\n",
      " [45]\n",
      " [35]\n",
      " [16]\n",
      " [ 7]\n",
      " [15]\n",
      " [32]\n",
      " [ 7]\n",
      " [26]\n",
      " [34]\n",
      " [42]\n",
      " [41]\n",
      " [50]\n",
      " [50]\n",
      " [15]\n",
      " [33]\n",
      " [19]\n",
      " [35]\n",
      " [ 9]\n",
      " [10]\n",
      " [37]\n",
      " [50]\n",
      " [26]\n",
      " [35]\n",
      " [27]\n",
      " [ 6]\n",
      " [31]\n",
      " [33]\n",
      " [ 9]\n",
      " [ 1]\n",
      " [ 4]\n",
      " [15]\n",
      " [15]\n",
      " [ 5]\n",
      " [38]\n",
      " [ 8]\n",
      " [ 5]\n",
      " [26]\n",
      " [50]\n",
      " [10]\n",
      " [ 8]\n",
      " [ 5]\n",
      " [ 7]\n",
      " [11]\n",
      " [44]\n",
      " [24]\n",
      " [30]\n",
      " [10]\n",
      " [17]\n",
      " [29]\n",
      " [34]\n",
      " [31]\n",
      " [11]\n",
      " [ 4]\n",
      " [13]\n",
      " [11]\n",
      " [37]\n",
      " [10]\n",
      " [19]\n",
      " [10]\n",
      " [ 8]\n",
      " [48]\n",
      " [36]\n",
      " [33]\n",
      " [ 8]\n",
      " [21]\n",
      " [20]\n",
      " [ 2]\n",
      " [45]\n",
      " [34]\n",
      " [42]\n",
      " [ 6]\n",
      " [21]], shape=(100, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[ 1 42 38 19 44 35 15 46 50 14 19 20 19  2  3  7  1 48  9 46 18  6  4  2\n",
      " 31 49  3 16 45 35 16  7 15 32  7 26 34 42 41 50 50 15 33 19 35  9 10 37\n",
      " 50 26 35 27  6 31 33  9  1  4 15 15  5 38  8  5 26 50 10  8  5  7 11 44\n",
      " 24 30 10 17 29 34 31 11  4 13 11 37 10 19 10  8 48 36 33  8 21 20  2 45\n",
      " 34 42  6 21], shape=(100,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# 1. 随机采样\n",
    "# 2. 贪心\n",
    "# 3. logits : 在计算分类问题总, softmax 之前的值就是logits\n",
    "# num_samples 指定产生多个序列\n",
    "sample_indices = tf.random.categorical(logits=example_batch_predictions[0], num_samples=1)\n",
    "print(sample_indices)\n",
    "sample_indices = tf.squeeze(sample_indices, axis=-1)\n",
    "print(sample_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input  '  t h e   o f f e r   w h i c h   v a l u e s   t h e   w h o l e   o f   c o a t e s   a t   #   N   m i l l i o n   h a s   a l r e a d y   b e e n   a c c e p t e d   b y   c o a t e s   e x e c u'\n",
      "Output  't h e   o f f e r   w h i c h   v a l u e s   t h e   w h o l e   o f   c o a t e s   a t   #   N   m i l l i o n   h a s   a l r e a d y   b e e n   a c c e p t e d   b y   c o a t e s   e x e c u t'\n",
      "Prediction   \"  s o 9 u l 5 w unk 4 9 < 9 # $ -   y / w 8 * & # h z $ 6 v l 6 - 5 i - c k s r unk unk 5 j 9 l / 0 n unk c l d * h j /   & 5 5 ' o . ' c unk 0 . ' - 1 u a g 0 7 f k h 1 & 3 1 n 0 9 0 . y m j . > < # v k s * >\"\n"
     ]
    }
   ],
   "source": [
    "# 打印输入和输出\n",
    "print(\"Input \", repr(\" \".join(id2char[input_example_batch[0]])))\n",
    "print(\"Output \", repr(\" \".join(id2char[target_example_batch[0]])))\n",
    "print(\"Prediction  \", repr(\" \".join(id2char[sample_indices])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3. 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return keras.losses.sparse_categorical_crossentropy(\n",
    "        labels, logits, from_logits=True # 因为预测值是 logits , 所以需要设置为 true\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100)\n",
      "3.9476264\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=loss)\n",
    "\n",
    "# 计算loss\n",
    "example_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(example_loss.shape)\n",
    "print(example_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4. 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "362/789 [============>.................] - ETA: 22s - loss: 2.1440"
     ]
    }
   ],
   "source": [
    "# 定义文件夹保存模型\n",
    "output_dir = \"./text_generation_checkpoints\"\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "checkpoint_prefix = os.path.join(output_dir, 'ckpt_{epoch}')\n",
    "# 定义回调函数\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix, save_weights_only=True),\n",
    "    keras.callbacks.EarlyStopping(patience=5, min_delta=1e-3)\n",
    "]\n",
    "\n",
    "epochs = 40\n",
    "history = model.fit(seq_dataset, epochs=epochs, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "{'loss': [1.7963497638702393,\n  1.2682101726531982,\n  1.1677029132843018,\n  1.1214680671691895,\n  1.0925670862197876,\n  1.0723893642425537,\n  1.0574251413345337,\n  1.0453972816467285,\n  1.0356159210205078,\n  1.0284011363983154,\n  1.0222655534744263,\n  1.0172481536865234,\n  1.0133591890335083,\n  1.0100384950637817,\n  1.0072368383407593,\n  1.0053337812423706,\n  1.0036914348602295,\n  1.0030094385147095,\n  1.0029821395874023,\n  1.002568006515503,\n  1.0027647018432617,\n  1.0036383867263794,\n  1.0043693780899048,\n  1.0054091215133667,\n  1.0073111057281494,\n  1.008745551109314,\n  1.0116959810256958,\n  1.0137498378753662,\n  1.0165047645568848,\n  1.0189013481140137,\n  1.0228221416473389,\n  1.0262104272842407,\n  1.031156301498413,\n  1.0362390279769897,\n  1.04008948802948,\n  1.0501790046691895,\n  1.0583056211471558,\n  1.0672812461853027,\n  1.0777320861816406,\n  1.1291507482528687]}"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前模型的困惑度 :  2.886769057926001\n"
     ]
    }
   ],
   "source": [
    "# 计算困惑度\n",
    "loss =  np.array(history.history['loss'])\n",
    "\n",
    "# 计算困惑度 : exp(loss.mean())\n",
    "print(\"当前模型的困惑度 : \", np.exp(loss.mean()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. 模型载入"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'./text_generation_checkpoints\\\\ckpt_40'"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "# 载入权重\n",
    "new_model.load_weights(tf.train.latest_checkpoint(output_dir))\n",
    "# None 指的是输入可以是变长的序列\n",
    "new_model.build(tf.TensorShape([1, None]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}