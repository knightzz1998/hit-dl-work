{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1. 使用 sklearn 对文档进行向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jobs was the chairman of Apple Inc., and he was very famous',\n",
       " 'I like to use apple computer',\n",
       " 'And I also like to eat apple']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建语料库\n",
    "corpus = [\n",
    "    'Jobs was the chairman of Apple Inc., and he was very famous',\n",
    "    'I like to use apple computer',\n",
    "    'And I also like to eat apple'\n",
    "]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 1.1 未经停用词过滤的文档向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(matrix([[0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 2],\n",
       "         [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0],\n",
       "         [1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]], dtype=int64),\n",
       " {'jobs': 9,\n",
       "  'was': 16,\n",
       "  'the': 12,\n",
       "  'chairman': 3,\n",
       "  'of': 11,\n",
       "  'apple': 2,\n",
       "  'inc': 8,\n",
       "  'and': 1,\n",
       "  'he': 7,\n",
       "  'very': 15,\n",
       "  'famous': 6,\n",
       "  'like': 10,\n",
       "  'to': 13,\n",
       "  'use': 14,\n",
       "  'computer': 4,\n",
       "  'also': 0,\n",
       "  'eat': 5})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "# 将文档转换为完整的特征向量矩阵\n",
    "vectorizer.fit_transform(corpus).todense(), vectorizer.vocabulary_ # 输出文档特征向量矩阵和词频"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 1.2 使用停用词过滤后的文档向量化\n",
    "- 停用词下载如果出现问题可参考 : [停用词下载](http://knightzz.cn/archives/nltk-tong-yong-ci-xia-zai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 下载停用词\n",
    "# nltk.download()\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after stopwords removal:   [[0 1 1 0 0 1 1 1 0 0]\n",
      " [0 1 0 1 0 0 0 0 1 1]\n",
      " [1 1 0 0 1 0 0 0 1 0]]\n",
      "after stopwords removal:   {'jobs': 7, 'chairman': 2, 'apple': 1, 'inc': 6, 'famous': 5, 'like': 8, 'use': 9, 'computer': 3, 'also': 0, 'eat': 4}\n"
     ]
    }
   ],
   "source": [
    "# 使用停用词过滤进行文档向量化\n",
    "vectorizer = CountVectorizer(stop_words=stopwords)\n",
    "print(\"after stopwords removal:  \", vectorizer.fit_transform(corpus).todense())\n",
    "print(\"after stopwords removal:  \", vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 1.3 采用ngram模式进行文档向量化\n",
    "- N‐gram通常是指一段文本或语音中连续N个项目（item）的序列。项目（item）可以是单词、字母、碱基对等。\n",
    "- N=1时称为uni‐gram，N=2称为bi‐gram，N=3称为tri‐gram，以此类推\n",
    "- 举例:对于文本‘And l also like to eat apple'，则\n",
    "    1. Uni-gram: And,l, also,like, to, eat, apple\n",
    "    2. Bi-gram: And l, l also，also like，like to, to eat, eat apple.\n",
    "    3. Tri-gram: And l also, l also like, also like to, like to eat, to eat apple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-gram mode:      [[0 0 1 0 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 0 0 0 1 1 2 1 1]\n",
      " [0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0]\n",
      " [1 1 1 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0]]\n",
      "N-gram mode:          {'jobs': 18, 'was': 33, 'the': 24, 'chairman': 8, 'of': 22, 'apple': 5, 'inc': 16, 'and': 2, 'he': 14, 'very': 31, 'famous': 13, 'jobs was': 19, 'was the': 34, 'the chairman': 25, 'chairman of': 9, 'of apple': 23, 'apple inc': 7, 'inc and': 17, 'and he': 4, 'he was': 15, 'was very': 35, 'very famous': 32, 'like': 20, 'to': 26, 'use': 29, 'computer': 10, 'like to': 21, 'to use': 28, 'use apple': 30, 'apple computer': 6, 'also': 0, 'eat': 11, 'and also': 3, 'also like': 1, 'to eat': 27, 'eat apple': 12}\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,2)) #表示从1-2，既包括 unigram，也包括 bigram 模式的文本\n",
    "print(\"N-gram mode:     \",vectorizer.fit_transform(corpus).todense())  #转化为完整特征矩阵\n",
    "print(\"N-gram mode:         \",vectorizer.vocabulary_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
